{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <span style=\"color:blue; font-family:Georgia;  font-size:2em;\">\n",
    "        <h1>Clustering data - Crisp Algorithms</h1></span>\n",
    " </center>\n",
    "        <p> </p>\n",
    "        <p> </p>\n",
    "        <center><span style=\"color:blue; font-family:Georgia;  font-size:1em;\">\n",
    "        Ramon BÃ©jar Torres</span></center>\n",
    "        <canvas id=\"myCanvas\" width=\"200\" height=\"100\" style=\"border:0px solid\"></canvas>\n",
    "        <center>Data mining - Master on Computer Science</center>\n",
    "        <center><img src=\"M-UdL2.png\"  width=\"200\" alt=\"UdL Logo\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are going to discuss in this notebook an approach to the problem of clustering data sets. We consider data sets of points, where each point is considered to be a $d-$ dimensional numeric vector in an euclidean space.\n",
    "\n",
    "Given a data set, a cluster is a subset of points of the data set that are somehow related to each other.\n",
    "\n",
    "That is, they share some similar features, or we say that globally they form a group of related/similar points. \n",
    "\n",
    "For example, consider different demografic and economic variables for the countries. Do we observe a clear division between countries when  looking at those indicators ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That we assume an euclidean space is at least necessary for the two algorithms we present here, k-means and Bisecting k-means, as they consider euclidean distances between points when measuring how close is each point to its cluster center, and the variance within each cluster produced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The algorithms we consider here are examples of **unsupervised learning** algorithms:\n",
    "- They learn to what cluster belongs each data point without the prior knowledge of any *good* examples of points already well linked to their clusters.\n",
    "- So, the algorithms work without practical clues about what points contain each cluster. In other words, they **discover** concepts without prior human assistance about how are the concepts they should find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/share/spark-3.0.1-bin-hadoop2.7 <SparkContext master=local[*] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Our preliminary set-up code\n",
    "#\n",
    "\n",
    "import pyspark\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "print (spark_home, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exact (crisp) clustering with Lloyd algorithm (k-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first consider the problem of **exact** clustering. We assume that there exist k clusters (groups of points), and that each point in our data set belongs to **exactly one** of the k clusters. We start assuming that we know the right number of clusters $k$, although this value is usually something we have to guess in real applications of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For presenting the algorithm, we need to introduce some definitions:\n",
    "\n",
    "- Target set of data points: Target set of $n$-dimensional points $D=\\{X_1,X_2,\\ldots,X_m \\}$\n",
    "\n",
    "- Euclidean distance between two points: $ || x-y || = \\sqrt{ \\sum_{i = 1}^{n} (x_i-y_i)^2 } $  \n",
    "\n",
    "- Centroid or center of a subset Y:  $  \\frac{1}{|Y|} \\sum_{y \\in Y} y $ \n",
    "\n",
    "- Within-cluster sum of square errors (WCSSE) for a set of clusters C: \n",
    "$$ \\sum_{c \\in C} \\sum_{x \\in c} || x-center(c) ||^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, Lloyd algorithm considers that a cluster:\n",
    "- Is defined simply by its center\n",
    "- The set of points that belong to a cluster is the set of points with smaller euclidean distance to that center than to any other cluster center.\n",
    "\n",
    "We can think about the cluster center as being the mean representative point of the cluster \n",
    "> Observe that it can be the case that there is no single point in our data set that is exactly equal to that cluster center.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, Lloyd algorithm finds a set of k clusters with the following iterative WCSSE improving algorithm:\n",
    "\n",
    "```python\n",
    "clusters = Initial Guess for k clusters centers  \n",
    "iters = 1  \n",
    "while (clusters changed significantly  &   iters <= limit) do:  \n",
    "  # Assign closest cluster to each point\n",
    "  for p in D:\n",
    "      clusterFor(p) = NearestClusterCenter(clusters,p)     \n",
    "  # Find best new set of cluster centers   \n",
    "  for c in [1,2,...,k]: \n",
    "      clusters(c) = centroid(points in D assigned to c)  \n",
    "  iters = iters + 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the two conditions to stop modifying the clusters:\n",
    "- the first one refers to measuring the difference of the clusters between the previous iterations and the current one. We need to define what we mean by *changed significantly*, but usually that means that the distance between at least one pair (old_center_i,new_center_i), for some cluster i, is greater than certain threshold value. \n",
    "- the second one is about reaching some maximum number of iterations. This is always necessary, as k-means may need sometimes a big number of iterations to reach the desired optimal clusters. Actually, it has been proven that there are cases where it needs an exponential number of iterations:\n",
    "> \"k-means Requires Exponentially Many Iterations Even\n",
    "in the Plane\" https://cseweb.ucsd.edu/~avattani/papers/kmeans.pdf\n",
    "\n",
    "\n",
    "In the Spark implementation of k-means, we can specify these two stopping conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel implementation in the Map-Reduce framework\n",
    "\n",
    "The k-means algorithm we have just presented is a good example of an interesting algorithm to think about an efficient implementation in a Map-Reduce framework, and in the particular Spark programming framework where we can benefit from the memory-based, resilient distributed data sets(RDDs).\n",
    "\n",
    "First, regarding the data needed to store our current *model* for the clusters, observe that they are simply a set of k d-dimensional points (representing the centers of each cluster). So, assuming k is a small number compared with the total number of points in D, we are going to assume that the set of cluster centers can be distributed among all the workers in our spark application. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's analyze how to implement the two steps performed in every iteration of Lloyd algorithm. \n",
    "- In the first step, we have to assign to each data point its closest cluster center. This is clearly a map operation that can be performed locally with each point, using  (key,value) pairs, where the key is the cluster center assigned and the value is a point assigned to that cluster center:\n",
    "$$ map : point \\ p \\Rightarrow (nearestCenter(Clusters,p),p) $$\n",
    "\n",
    "\n",
    "- In the second step, we have to compute the centroid of each set of points assigned to the same cluster center. So, in this case this is clearly a reduceByKey operation, where the reduce operation for two points assigned to the same cluster center is simply: p1+p2 (coordinate wise addition).\n",
    "$$ reduceByKey : points \\ (c,p1),(c,p2) \\Rightarrow (c,p1+p2)$$\n",
    "Once we have all the points of every cluster added, we simply divide by the number of points of each cluster to get its centroid. So, we obtain the new cluster centers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example domain: clustering countries\n",
    "\n",
    "Consider the following data set of countries where we include the birth rate and death rate of every country in the data set. We will try to discover if there are any subgroups of countries, regarding their similarites in these two demographic indicators, using the k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#  Country information about birth rate (2nd col) and death rate (3th col):\n",
    "#  The complete countries data set can be found at: data/countries_data.csv\n",
    "#\n",
    "countriesdata = [ [ 'Afghanistan', 38.6, 19 ], \\\n",
    "                  [ 'Armenia', 13.6, 9.3 ], \\\n",
    "                  [ 'India',  19.6  ,  7.3 ], \\\n",
    "                  [ 'Iran', 18  ,  5.9 ], \\\n",
    "                  [ 'Iraq', 31.5  ,  3.8 ], \\\n",
    "                  [ 'Yemen', 30  ,  6.3 ], \\\n",
    "                  [ 'Israel', 18.5  ,  5.2 ], \\\n",
    "                  [ 'Italy',  8.7  ,  10.2  ], \\\n",
    "                  [ 'Germany'  ,  8.5  ,  11.4 ], \\\n",
    "                  [  'Denmark'  ,  10.3  ,  10.3    ], \\\n",
    "                  [  'France'  ,  12.4  ,  9.2    ], \\\n",
    "                  [  'Spain'  ,  9.6  ,  9     ], \\\n",
    "                  [ 'Austria'  ,  9.4  ,  9.4  ], \\\n",
    "                  [ 'Switzerland'  ,  10.5  ,  8.1 ], \\\n",
    "                  [  'Ecuador'  ,  18.5  ,  5.1 ], \\\n",
    "                  [  'Peru'  ,  18.3  ,  6 ], \\\n",
    "                  [  'Bolivia'  ,  22.8  ,  6.5 ], \\\n",
    "                  [  'Brazil'  ,  14.5  ,  6.6, ], \\\n",
    "                  [ 'Argentina'  ,  16.6  ,  7.3 ], \\\n",
    "                  [  'Chile'  ,  13.8  ,  6    ], \\\n",
    "                  [  'Colombia'  ,  16.5  ,  5.4 ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are going to use the implementation of k-means available in spark, that incorporates an alternative way of creating the initial set of cluster centers (apart of the method of picking uniformly at random k points). But in this notebook we will not explore the alternative ways to create the initial centers, although they can have a big impact in the needed number of iterations to achieve good results. Check the paper:\n",
    "\n",
    "> B. Bahmani, B. Moseley, A. Vattani, R. Kumar and S. Vassilvitskii. *Scalable K-Means++*. In Proceedings of PVLDB 5(7): 622-633. URL: http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf (2012)\n",
    "\n",
    "If you want to know more about the specific alternative centers initialization available in the k-means implementation available in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "\n",
    "# Evaluate the error of a point, computed with its distance to the predicted cluster center\n",
    "# (Within Cluster Sum of Squared Errors)\n",
    "def error(clusters,point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sum([x**2 for x in (point - center)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.71  6.13]\n",
      "[33.36666667  9.7       ]\n",
      "[10.375   9.6125]\n"
     ]
    }
   ],
   "source": [
    "countriesRDD = sc.parallelize( countriesdata ).map( lambda p : np.array(p[1:]) )\n",
    "countriesRDD.persist()\n",
    "\n",
    "# Cluster the data in 3 clusters\n",
    "countriesclusters1 = KMeans.train( countriesRDD, 3, maxIterations=20, \\\n",
    "                               initializationMode=\"random\")\n",
    "#Show clusters centers:\n",
    "for c in countriesclusters1.centers:\n",
    "    print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster for  Afghanistan  :  1\n",
      "Cluster for  Armenia  :  2\n",
      "Cluster for  India  :  0\n",
      "Cluster for  Iran  :  0\n",
      "Cluster for  Iraq  :  1\n",
      "Cluster for  Yemen  :  1\n",
      "Cluster for  Israel  :  0\n",
      "Cluster for  Italy  :  2\n",
      "Cluster for  Germany  :  2\n",
      "Cluster for  Denmark  :  2\n",
      "Cluster for  France  :  2\n",
      "Cluster for  Spain  :  2\n",
      "Cluster for  Austria  :  2\n",
      "Cluster for  Switzerland  :  2\n",
      "Cluster for  Ecuador  :  0\n",
      "Cluster for  Peru  :  0\n",
      "Cluster for  Bolivia  :  0\n",
      "Cluster for  Brazil  :  0\n",
      "Cluster for  Argentina  :  0\n",
      "Cluster for  Chile  :  0\n",
      "Cluster for  Colombia  :  0\n",
      "Within Cluster Sum of Squared Error = 269.5404166666667\n",
      "Average Square Error = 12.835257936507938\n"
     ]
    }
   ],
   "source": [
    "print (\"\")\n",
    "cpredictions = {}\n",
    "for country in countriesdata:\n",
    "    cpredictions[country[0]] = countriesclusters1.predict(np.array(country[1:]))\n",
    "    print (\"Cluster for \", country[0], \" : \", cpredictions[country[0]])\n",
    "\n",
    "WCSSE = countriesRDD.map(lambda point: error(countriesclusters1,point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Cluster Sum of Squared Error = \" + str(WCSSE))\n",
    "print(\"Average Square Error = \"+ str(WCSSE/countriesRDD.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we execute k-means with the countries data set, almost all the executions obtain a model with WCSSE around 269 (with an average square error per point around 12), although some of them achieve a bigger error.\n",
    "\n",
    "Because we have only two dimensions per point, we can easily plot the points of each cluster to visually inspect if the clusters learned make any sense. We can do this with a 2D plot that we make with matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAIECAYAAAAXc89kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyt0lEQVR4nO3dfZjdZ10n/venUzJi25kUCJptUgsEWbdWypOAayAVEVHkIZa9FP0J7LWrIGCq7rIUdVlFF3zYPiisrq48uCu6Sw0iixUFWw0rqOhSsCBLNNAmjRChmSlsSej0/v1xztDJZGbyncmZOWdmXq/rOtc55/4+zIf58oV5576/912ttQAAAHBm5wy7AAAAgPVCgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOjo3GEXsNqqqpL8kyR3DbsWAABg6C5Ickdrra3k4A0foNILT4eHXQQAADAydiQ5spIDN0OAuitJbr/99kxMTAy7FgAAYEimp6ezc+fO5CxGp22GAJUkmZiYEKAAAICzYhIJAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjgQoAACAjs4ddgEAAMAGNTOTHDiQHD2abN+e7N6djI0Nu6qzIkABAACDt39/sm9fcvjwfW07diTXX5/s3Tu8us6SIXwAAMBg7d+fXHnlqeEpSY4c6bXv3z+cugZAgAIAAAZnZqbX89Ta6dtm2666qrffOiRAAQAAg3PgwOk9T3O1ltx+e2+/dUiAAgAABufo0cHuN2IEKAAAYHC2bx/sfiNGgAIAAAZn9+7ebHtVC2+vSnbu7O23DglQAADA4IyN9aYqT04PUbPfr7tu3a4HJUABAACDtXdvcsMNyUUXndq+Y0evfR2vA1VtoekFN5CqmkgyNTU1lYmJiWGXAwAAm8fMTG+2vaNHe8887d491J6n6enpTE5OJslka216Jec4d7AlAQAA9I2NJXv2DLuKgTKEDwAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoKOhBqiqelJVvaOq7qiqVlXPnrf9/Kp6XVUdrqq7q+ojVfWiIZULAABscsPugTovyS1JXrLI9muSfGuS703yNUmuS/K6qnrmmlQHAAAwx7nD/OGttRuT3JgkVbXQLt+Q5M2ttZv733+1qn4gydcn+b21qBEAAGDWsHugzuTPkjyzqi6qniuSfHWSP1zsgKoar6qJ2VeSC9aqWAAAYGMb9QD1siQfSXI4yckkf5DkJa21P13imKuTTM15HV7tIgEAgM1hPQSoJyR5ZpLHJPnRJK+vqm9e4pjXJJmc89qx2kUCAACbw1CfgVpKVd0/yX9M8pzW2jv7zR+qqsuT/Jsk717ouNbaiSQn5pxnlSsFAAA2i1Hugbpf/3XvvPaZjHbdAADABjXUHqiqOj/JrjlND+n3MH22tXZbVf1Jkp+vqruTfDLJk5N8X5IfWfNiAQCATW/YQ/gem+SmOd+v6b+/OckLknxXes80/WaSB6QXon4sya+sXYkAAAA9w14H6uYkiz6k1Fr7hyQvXLOCAAAAluBZIgAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI6GGqCq6klV9Y6quqOqWlU9e4F9vqaqfq+qpqrq81X1l1V18RDKBQAANrlh90Cdl+SWJC9ZaGNVPSzJe5P8bZI9Sb4uyauTfGGN6gMAAPiSc4f5w1trNya5MUmqaqFdfibJ77fWXj6n7e/WoDQAAIDTDLsHalFVdU6Sb0/yf6vqXVX16ar684WG+QEAAKyFkQ1QSR6c5Pwkr0jyB0m+JcnbkuyvqicvdlBVjVfVxOwryQVrUi0AALDhDXUI3xnMhru3t9au7X/+YFV9Q5IXJfmTRY67OsmrVrs4AABg8xnlHqh/THJPko/Ma/9okqVm4XtNksk5rx2rUh0AALDpjGwPVGvtZFX9ZZJHzNv01Uk+ucRxJ5KcmP2+yOQUAAAAyzbUAFVV5yfZNafpIVV1eZLPttZuS/LzSf5HVf1pkpuSfGuS70hvSnMAAIA1NeweqMemF4xmXdN/f3OSF7TW3lZVL0rvuaZfTPKxJN/ZWnvv2pYJAACQVGtt2DWsqv5MfFNTU1OZmJgYdjkAAMCQTE9PZ3JyMkkmW2vTKznHKE8iAQAAMFIEKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI4EKAAAgI6GGqCq6klV9Y6quqOqWlU9e4l9f6W/z1VrVyEAAMB9ht0DdV6SW5K8ZKmdquo5SZ6Q5I61KAoAAGAh5w7zh7fWbkxyY5JU1YL7VNVFSX4pydOSvHPNigMAAJhnqAHqTKrqnCT/LcnPt9ZuXSxkzTtmPMn4nKYLVqk8AABgkxn2EL4z+XdJ7knyi8s45uokU3Neh1ehLgAAYBMa2QBVVY9Jsi/JC1prbRmHvibJ5JzXjlUoDwAA2IRGNkAl2Z3kwUluq6p7quqeJF+V5D9V1ScWO6i1dqK1Nj37SnLX2pQLAABsdKP8DNR/S/LueW3v6re/ce3LAQAANruhBqiqOj/JrjlND6mqy5N8trV2W5LPzNv/i0n+obX2sbWrEgAAoGfYPVCPTXLTnO/X9N/fnOQFa14NAADAEoa9DtTNSc48N/l9+1+yasUAAACcwShPIgEAADBSBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOBCgAAICOVhygqmpXVT2tqu7f/16DKwsAAGD0LDtAVdUDq+rdSf5vkt9Psr2/6der6j8NsjgAAIBRspIeqGuT3JPk4iT/b077/0jyrYMoCgAAYBSdu4JjviXJ01prh+eN2vt4kq8aSFUAAAAjaCU9UOfl1J6nWQ9IcuLsygEAABhdKwlQB5J835zvrarOSfLyJDcNpCoAAIARtJIhfC9P8p6qemySLUl+Lsml6fVA/fMB1gYAADBSlt0D1Vr7myRfneS9Sd6e3pC+/Uke1Vr7u8GWBwAAMDqW3QNVVRcnub219jMLbWut3TaQygAAAEbMSp6BOpRk2/zGqnpgfxsAAMCGtJIAVUnaAu3nJ/nC2ZUDAAAwujoP4auqa/ofW5JXV9XcqczHkjw+yQcHVxoAAMBoWc4zUI/qv1eSy5KcnLPtZJJbkvzCgOoCAAAYOZ0DVGvtiiSpqjcm2ddam161qgAAAEbQsmfha629cDUKAQAAGHUrWUg3/UV0/0WSi9NbTPdLWmt7l3GeJyX5t0kek2R7kue01n63v+1+SX46ybcleWiSqSTvTvKK1todK6kbAADgbCx7Fr6q+q4kf5bka5I8J8n9klya5JvSCznLcV56z069ZIFtX57k0Ule3X/fm+QRSX5vuTUDAAAMwkp6oF6Z5Idba6+vqruS7Etv/af/kuTock7UWrsxyY1JUlXzt00leerctqp6aZK/sGAvAAAwDCtZB+phSd7Z/3wyyXmttZbk2iTfP6jCFjGZ3jTqxxfboarGq2pi9pXkglWuCQAA2CRWEqDuzH2h5EiSr+1/3presLtVUVVfluRnk/zWGWYAvDq9oYSzr8OrVRMAALC5rCRA/WnuG1r31iTXV9WvJfmtJO8ZVGFz9SeU+J/prUH14jPs/pr0eqpmXztWoyYAAGDzWckzUC9N8mX9zz+T5ItJviHJ76Q3a95AzQlPX5Xkm860/lRr7USSE3OOH3RJAADAJrWsAFVV5yZ5RpJ3JUlr7d4kr12FumZ/3mx4eniSK1prn1mtnwUAAHAmywpQrbV7qupX0pvC/KxV1flJds1pekhVXZ7ks+nN6HdDelOYPyPJWFV9ZX+/z7bWTg6iBgAAgK5WMoTvL5JcnuSTA/j5j01y05zv1/Tf35zkPyR5Zv/7B+cdd0WSmwfw8wEAADpbSYD6z0muqaqdSf4qyefnbmytfajriVprN6c3McRiPMAEAACMjJUEqN/uv//inLaWXthpScbOtigAAIBRtJIA9ZCBVwEAALAOLDtAtdYG8ewTAADAurOShXQBAAA2pZUM4WMF2kzL8QPHc/LoyWzZviVbd29NjZkjAwAA1hMBag0c238sB/cdzInDJ77UNr5jPLuu35Vte7cNsTIAAGA5DOFbZcf2H8utV956SnhKkhNHTuTWK2/Nsf3HhlQZAACwXCsOUFW1pap2VNXFc1+DLG69azMtB/cd7E3uftrG3tvBqw6mzSy0AwAAMGqWHaCq6uFVdSDJ3Uk+meRQ//WJ/jt9xw8cP63n6RQtOXH7iRw/cHzNagIAAFZuJc9AvSnJPUmekeRoFu5fIcnJoycHuh8AADBcKwlQlyd5TGvtbwdcy4azZfuWge4HAAAM10qegfpIkgcNupCNaOvurRnfMZ4sNlt5JeM7x7N199a1LAsAAFihTgGqqiZmX0n+XZKfq6o9VfXAudv62+mrscqu63f1v8zf2Hvbdd0u60EBAMA6Ua2d+RGmqro3pz7rVDn92adK0lprY4Mr7+z1Q93U1NRUJiaGk+8WXAdq53h2XWcdKAAAWCvT09OZnJxMksnW2vRKztH1GagrVnJyerbt3ZYHPetBOX7geE4ePZkt27dk6+6tep4AAGCd6RSgWmt/Mvu5v9bT7W1e11VVVZKdgy1v46ixyoV7Lhx2GQAAwFlYySQSh5IsNO7sAbEOFAAAsIGtJEAt9PxTkpyf5AtnVw4AAMDo6rwOVFVd0//Ykry6qv7fnM1jSR6f5IODKw0AAGC0LGch3Uf13yvJZUlOztl2MsktSX5hQHUBAACMnM4BqrV2RZJU1RuT7FvptH8AAADr1XJ6oJIkrbUXrkYhAAAAo27ZASpJquqxSf5FkouTbJm7rbW2dwB1AQAAjJxlz8JXVd+V5M+SfE2S5yS5X5JLk3xTkqmBVgcAADBCVjKN+SuT/HBr7TvSmzxiX5J/muR/JrltgLUBAACMlJUEqIcleWf/88kk57XWWpJrk3z/oAoDAAAYNSsJUHcmuaD/+UiSr+1/3prkywdQEwAAwEhaySQSf5rkqUk+nOStSa6vqm/qt71ngLUBAACMlJUEqJcm+bL+559J8sUk35Dkd5L89IDqAgAAGDkrWQfqs3M+35vktQOtCAAAYESt5BmoVNXDquqnq+q3qurB/banV9Wlgy0PAABgdKxkHagnp/f80+OT7E1yfn/TI5P85OBKAwAAGC0r6YF6bZIfb609Nb1pzGf9cZInDKQqAACAEbSSAHVZkrct0P7pJA86u3IAAABG10pm4TueZHuSQ/PaH5XeulCsY22m5fiB4zl59GS2bN+Srbu3psZq2GUBAMBIWEmA+u0kP1tVz03SkpxTVf88yS8k+Y1BFsfaOrb/WA7uO5gTh098qW18x3h2Xb8r2/ZuG2JlAAAwGlYyhO+VSf42ye3pTSDxkfQW1/2zWAdq3Tq2/1huvfLWU8JTkpw4ciK3Xnlrju0/NqTKAABgdFRrbWUHVl2c5GvTC1H/p7X28UEWNihVNZFkampqKhMTE8Mu5xSjMlyuzbS8/5L3nxaevqR6PVFPOPQEw/kAAFi3pqenMzk5mSSTrbXplZxjJUP4kiSttduS3LbS4ze7URoud/zA8cXDU5K05MTtJ3L8wPFcuOfCtSsMAABGTKcAVVXXdD1ha+1HVl7O5jA7XC7zOv9mh8tdesOlaxqiTh49eeadlrEfAABsVF17oB417/uj+8d+rP/9q5PMJPmrAdW1YbWZloP7Dp4Wnnobk1Ry8KqDedCzHrRmw+W2bN8y0P0AAGCj6hSgWmtXzH6uqh9JcleS57fW7uy3XZjkjUkOrEaRG8koDpfbuntrxneM58SREwsHu/4zUFt3b12TegAAYFStZBa+H01y9Wx4SpL+5x/vb2MJozhcrsYqu67f1f8yf2Pvbdd1u0wgAQDApreSADWRZKEHdLYluWA5J6qqJ1XVO6rqjqpqVfXsedurqn6qqo5W1d1V9e6qevgKah4Zozpcbtvebbn0hkszftH4Ke3jO8bX/JksAAAYVSuZhe9tSd5YVT+a5C/6bY9P8vNJ9i/zXOcluSXJGxY59uVJfijJ85McSvLqJO+qqn/WWvvCCmofulEeLrdt77Y86FkPGomp1QEAYBStJEC9KMkvJHlLkvv12+5J8utJ/u1yTtRauzHJjUlSdeof6dVruCrJT7fW3t5v+74kn0ry7CS/vYLah252uNytV97aGx43N0SNwHC5GitTlQMAwCKWPYSvtfb/Wms/mOSB6c3O96gkD2it/WBr7fMDrO0hSb4yybvn/OypJH+e5ImLHVRV41U1MfvKMocVrgXD5QCATeWLX1ydfWEIzmYh3c8n+dAAa5nvK/vvn5rX/qk52xZydZJXrUpFA2S4HACwKXzuc8m3fVvy9KcnV1+99L533pl8y7ckL3hB8pKXrEl5sFwrDlAj7DVJ5i78e0GSw0OqZUmGywEAG9rnPtcLTu99b3Kgv9rNYiHqzjuTpz41+au/Sj7wgV6bEMUIWsksfGvlH/rvXzGv/SvmbDtNa+1Ea2169pXemlUsod3b8olXfyInji6xPtXsvjMth151KF/8jO51AGAJ99zT63l673vva3vlK5PXvOb0feeGp1kvfWnyhjesfp2wTKMcoA6lF5SeMtvQf6bp8UneN6yiNpp2b8vHX/LxfOLffyIfvOKDS4aoNtPy0e/7aD75U5/MLd98ixAFACzu3HOT5z739Pb5IWqh8JQkF12U7N69ujXCCgw1QFXV+VV1eVVd3m96SP/7xa21luS6JD9eVc+sqsuS/EaSO5L87lAK3mBmw9Mdv3JHkuTuj929aIiaDU+ffsunkySf++DnhCgAYGkve1nyi794evtsiFoqPN10U/Lwdb38JxtU9XLKkH541Z4kNy2w6c2ttRf0pzL/ySTfn2Rrkvcm+cHW2v9dxs+YSDI1NTWViYmJs655I/niZ76Yv37iX+fuj999Svv9H3H/XH7T5Rnf3pslcH54mlXjlUf+4SOz9Ulb16pkAGA9+qVfSn7oh7rtKzyxiqanpzM5OZkkk/3HfZZtqAFqLQhQSztx5EQ+uOeDufvgwiFqy4O3LBqeLvu9y/KAb3nAWpYLAKxXXUKU8MQqE6A6EKDObNEQtev+Gb94PMf/+Pgp7cITALAiS4Uo4Yk1MIgANcqTSLBGxi8az+U3X57777r/Ke13H7xbeAIABud7v3fxbU97mvDEuiBAkWTxEDWX8AQArNjshBGLecMbFp7iHEaMAMWXjF80nke+55GLbn/Ef3mE8AQALN9is+3Nt9g6UTBCBKh1rM203HnznfnUb30qd958Z9rM2T3P1mZa/v7qv190+ydf88lOi+0CAHzJUlOVL/Q8lBDFiDt32AWwMsf2H8vBfQdz4vB9gWZ8x3h2Xb8r2/ZuW/b5FpuqfK7ZdaLmTnEOALCoLus87dp1epB65St771dfvTZ1wjLogVqHju0/lluvvPWU8JT0ZtO79cpbc2z/sWWdr0t4mrXUYrsAAF9yzz29iSHOtEjuUovt/vIvr36dsEwC1DrTZloO7juYLDRar9928KqDnYfzLbVI7te96+vyxMNPPH12PiHqNIMeTgkA69655yYvfnFSdV/bYlOVLxSiHvrQ5Nu/ffXrhGUSoNaZ4weOn9bzdIqWnLj9RI4fOH7Gcy0VnmZn21t0inMh6kuO7T+W91/y/txyxS356PM+mluuuCXvv+T9y+4JBIAN54UvTH7913sh6kzrPM0NUQ99aG/fiy9eu1qhI89ArTMnj54c2H73TN+Tz3/486e0LTRV+WyImr/Y7skjJ/OFT35hUz8PNTuccn6P4OxwyktvuHRFz6QBwIbxwhcm4+PJ4x535nWeXvay5Pzzk6c8RXhiZOmBWme2bN8ysP3ud+H98sj3PDLnXXZekqXXeZrfEzV2/lguu/GyTD5hchnVr521GFI36OGUALBhPe953RfJfeELhSdGmgC1zmzdvTXjO8aTWmSHSsZ3jmfr7q2dzrdl25Y88j2PzAVff8EZF8mdDVHnP+r8XHbjZdn6jd1+xlpbqyF1gxxOCQDA+iBArTM1Vtl1/a7+l/kbe2+7rtuVGlssYZ1uy7YtefT7Ht1pkdzxi8bzmA88ZqTD0yBnKFzKIIdTAgCwPghQ69C2vdty6Q2XZvyiU589Gt8xvuJnbuqc7oFrOfuupbUeUjfI4ZQAAKwPJpFYp7bt3ZYHPetBOX7geE4ePZkt27dk6+6ty+p52miWM6Tuwj0XnvXPmx1OeeLIiYVDW/VCbdfhlAAAjD4Bah2rsTotCLSZtmlD1VoPqZsdTnnrlbf2hk/ODVErHE4JAMBoE6A2kGP7j+XgvoOn9MKM7xjPrut3bYqptIcxpG52OOWCv/frNsfvHQBgM6nWNvYUy1U1kWRqamoqExMTwy5n1Sy2HtFsT8hmWI+ozbS8/5L3n3FI3RMOPWHgvUKbuecPAGC9mJ6ezuTkZJJMttamV3IOk0hsANYj6lmNGQqX87Mv3HNhvuK7vyIX7rlQeAIA2KAEqA3AekT3WY0ZCgEAYJZnoDYA6xGdygyFAACsFgFqA7Ae0ekWmqEQAADOliF8G8DsekSnPfczq5LxndYjAgCAsyVAbQDDnDwBAAA2EwFqgzB5AgAArD7PQG0gJk8AAIDVJUBtMCZPAACA1WMIHwAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEfnDrsARl+baTl+4HhOHj2ZLdu3ZOvuramxGnZZAACw5gQolnRs/7Ec3HcwJw6f+FLb+I7x7Lp+V7bt3TbEygAAYO0Zwseiju0/lluvvPWU8JQkJ46cyK1X3ppj+48NqTIAABiOkQ5QVTVWVa+uqkNVdXdV/V1V/URVGT+2ytpMy8F9B5O20Mbe28GrDqbNLLQDAABsTCMdoJL8uyQvTvLSJF/T//7yJC8bZlGbwfEDx0/reTpFS07cfiLHDxxfs5oAAGDYRv0ZqG9I8vbW2jv73z9RVd+d5OuHWNOmcPLoyYHuBwAAG8Go90D9WZKnVNVXJ0lVPTLJNya5cbEDqmq8qiZmX0kuWJtSN5Yt27cMdD8AANgIRr0H6rVJJpL8bVXNJBlL8mOttd9c4pirk7xqLYrbyLbu3prxHeM5ceTEws9BVW82vq27t651aQAAMDSj3gP1L5J8T5LnJXl0kucn+TdV9fwljnlNksk5rx2rXeRGVGOVXdfv6n+Zv7H3tuu6XdaDAgBgUxn1APXzSV7bWvvt1tqHW2v/Lcm16fUyLai1dqK1Nj37SnLXWhW70Wzbuy2X3nBpxi8aP6V9fMd4Lr3hUutAAQCw6Yz6EL4vT3LvvLaZjH7w2zC27d2WBz3rQTl+4HhOHj2ZLdu3ZOvurXqeAADYlEY9QL0jyY9V1W1Jbk3yqCQ/kuQNQ61qk6mxyoV7Lhx2GQAAMHSjHqBeluTVSf5zkgcnuSPJf0nyU8MsCgAA2JxGOkC11u5KclX/BQAAMFSeJQIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhIgAIAAOhopNeBAta3mZnkwIHk6NFk+/Zk9+5kbGzYVQ2f3wsArF8CFLAq9u9P9u1LDh++r23HjuT665O9e4dX17D5vQDA+mYIHzBw+/cnV155akhIkiNHeu379w+nrmHzewGA9a9aa8OuYVVV1USSqampqUxMTAy7HNjwZmaSSy45PSTMqur1uBw6tLmGrfm9AMDwTU9PZ3JyMkkmW2vTKzmHHihgoA4cWDwkJElrye239/bbTPxeAGBjEKCAgTp6dLD7bRR+LwCwMQhQwEBt3z7Y/TYKvxcA2BgEKGCgdu/uPctTtfD2qmTnzt5+m4nfCwBsDAIUMFBjY70puZPTw8Ls9+uu23wTJfi9AMDGIEABA7d3b3LDDclFF53avmNHr32zrnfk9wIA659pzIFVMzPTm1Xu6NHesz27d+thSfxeAGBYBjGNuQAFAABsCtaBAgAAWEMCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEfnDrsAYGEWWwUAGD0CFIyg/fuTffuSw4fva9uxI7n++mTv3uHVBQCw2RnCByNm//7kyitPDU9JcuRIr33//uHUBQBAUq21YdewqqpqIsnU1NRUJiYmhl0OLGlmJrnkktPD06yqXk/UoUOG87E5GMoKwCBNT09ncnIySSZba9MrOYceKBghBw4sHp6SpLXk9tt7+8FGt39/7x8Urrgied7zeu+XXKIXFoDhEqBghBw9Otj9YL0ylBWAUSVAwQjZvn2w+8F6NDPTm0RloRHms21XXdXbDwDWmgAFI2T37t4zTlULb69Kdu7s7QcblaGsAIwyAQpGyNhYb6ry5PQQNfv9uus8RM/GZigr68rMTHLzzclv/VbvXdcobHgCFIyYvXuTG25ILrro1PYdO3rtm30dqNaSv/mbbvvee29y662rWw+DZygr64aZTmBTMo05jCjTN5+uteRHfzR53euS3/md5Du+Y/F97703+YEfSH7zN5N3vCN5ylPWrk7Ozux0/keOLPwclOn8GQmzM53M/y/p7HAB/+IFI2kQ05gLUMC6MBuerr229/1+91s8RM2Gp//6X3vf739/IWq9mf3bNDn171N/mzISLNoH65Z1oIBN461vvS88JckXv5h853f2gtFc88NTktx9d2/f48fXpFQGwFBWRpqZTmBTE6CAdeHKK5N/+S9PbZsfohYKT0mvt+rNb062bl2TUhmQvXuTT3wiuemm5C1v6b0fOiQ8MQLMdAKb2rnDLgCgi3POSX7t13qf3/CG+9pnQ9Rb35r8r/+1cHh661uTZz1r7WplcMbGkj17hl0FzGOmE9jUPAMFrCv33pv86399aohajPAErAozncC65RkoYNOZ7YmaP5xvPuEJWDUW7YNNbeQDVFVdVFX/vao+U1V3V9WHq+qxw64LlmJdxdU1G6Je+MLF9+kSnlwnYMXMdAKb1kg/A1VVFyb530luSvL0JMeSPDzJncOsC5ayf3+yb9+pEzTt2NH7x0r/fzpY8//hd65zzvDPQ64TcNb27u39S41F+2BTGelnoKrqtUn+eWtt91mcwzNQrBnrKq6NxWbbm2t2nahv+7bT/7Z5+9tdJwDYjDb8QrpV9ZEk70qyI8mTkxxJ8p9ba7+2jHMIUKwJ6yqujS7hada55yaTk8lnPnNf20UXJV/4wqltc7lOALBxbYZJJB6a5MVJPp7kaUl+OckvVtXzFzugqsaramL2leSCtSmVzc66iqtvqXWe3va20yeWuOee04PSkSOLh6fEdQIAljbSz0ClF/A+0Fp7Zf/7/6mqr03yoiRvXuSYq5O8ai2Kg7msq7i6lgpPsxNGPPOZvbYuU5yfiesEACxk1Hugjib5yLy2jya5eIljXpNkcs5rx+qUBqeyruLquuGGMy+SOzs739OffvY/z3UCABYy6gHqfyd5xLy2r07yycUOaK2daK1Nz76S3LWaBcKs3bt7z84sNjNcVbJzZ28/lu+5z+3NmjdrsXWezjkn+Z7vWfnPcZ0AgKWMeoC6NskTquqVVbWrqp6X5PuTvH7IdcFprKu4uqqSa6/thagzLZI7f1mW5fyMxHUCABY30rPwJUlVPSO9YXkPT3IoyTVm4WOULbS+0M6dvT/KTY199lpLPvzh5Ou+bvF9usyI+IAHJPe/v+sEAJvJhp/GfBAEKIZhZsa6isM2uyZXcup6T3PXerL+JQBsLgJUBwIUbF56AwGAuQSoDgQo2Nz0BgIAswYRoEZ9HSiAszI2luzZM+wqAICNYtRn4QMAABgZAhQAAEBHhvABA+e5IwBgoxKggIFaaOa7HTt6iwyb+Q4AWO8M4QMGZnbtpfkL2B450mvfv384dQEADIoABQzEzEyv52mhlRFm2666qrcfAMB6JUABA3HgwOk9T3O1ltx+e28/AID1yjNQwEAcPTrY/YbB5BcAwJkIUMBAbN8+2P3WmskvAIAuDOEDBmL37l7gqFp4e1Wyc2dvv1Fj8gsAoCsBChiIsbFeb01yeoia/X7ddaM3JM7kFwDAcghQwMDs3ZvccENy0UWntu/Y0WsfxaFwJr8AAJbDM1DAQO3dmzzrWetnMoaNMPkFALB2BChg4MbGkj17hl1FNw9+8GD3AwA2NkP4AAAAOhKggE3t058e7H4AwMYmQAGb2npfvwoAWFsCFLCpref1qwCAtSdAAZvael2/CgAYDgEK2PTW4/pVAMBwVGtt2DWsqqqaSDI1NTWViYmJYZcDjLCZmfWzfhUAsHzT09OZnJxMksnW2vRKzmEdKIC+9bR+FQAwHIbwAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdCRAAQAAdLSuAlRVvaKqWlVdN+xaAACAzWfdBKiqelySH0jyoWHXAgAAbE7rIkBV1flJfjPJv05y55DLAQAANql1EaCSvD7JO1tr7x52IQAAwOZ17rALOJOq+q4kj07yuI77jycZn9N0wWrUBQAAbD4jHaCqameS65M8tbX2hY6HXZ3kVatXFQDACJqZSQ4cSI4eTbZvT3bvTsbGhl0VbDjVWht2DYuqqmcneVuSmTnNY0laknuTjLfWZuYds1AP1OGpqalMTEysbsEAAMOwf3+yb19y+PB9bTt2JNdfn+zdO7y6YMRMT09ncnIySSZba9MrOceoB6gLknzVvOY3JvnbJD/bWvubDueYSDIlQAEAG9L+/cmVVybz/6ar6r3fcIMQBX0bPkAtpKpuTvLB1tpVHfcXoACAjWlmJrnkklN7nuaq6vVEHTpkOB9kMAFqvczCBwDAfAcOLB6ekl6v1O239/YDBmKkJ5FYSGttz7BrAAAYCUePDnY/4Iz0QAEArFfbtw92P+CMBCgAgPVq9+7eM06zE0bMV5Xs3NnbDxgIAQoAYL0aG+tNVZ6cHqJmv193nQkkYIAEKACA9Wzv3t5U5RdddGr7jh2mMIdVsO6mMV8u05gDAJvCzExvtr2jR3vPPO3erecJ5hnENObrbhY+AAAWMDaW7Nkz7CpgwzOEDwAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoCMBCgAAoKNzh13AWpmenh52CQAAwBANIhNUa20ApYyuqrooyeFh1wEAAIyMHa21Iys5cDMEqEryT5LcNexaRswF6QXLHfG72Shc043HNd14XNONyXXdeFzTjWfuNU2SO9oKg9CGH8LX/8WsKF1uZL1cmSS5q7VmfOMG4JpuPK7pxuOabkyu68bjmm48g7ymJpEAAADoSIACAADoSIDavE4k+cn+OxuDa7rxuKYbj2u6MbmuG49ruvEM7Jpu+EkkAAAABkUPFAAAQEcCFAAAQEcCFAAAQEcCFAAAQEcC1AZXVU+qqndU1R1V1arq2fO2V1X9VFUdraq7q+rdVfXwIZVLBx2u6Zv67XNffzCkcumgqq6uqr+sqruq6tNV9btV9Yh5+3xZVb2+qj5TVZ+rqt+pqq8YVs0sreM1vXmBe/VXhlUzS6uqF1fVh6pquv96X1U9fc529+g60+GaukfXuap6Rf+6XTen7azvVQFq4zsvyS1JXrLI9pcn+aEkL0ry+CSfT/KuqvqytSmPFTjTNU2SP0iyfc7ru9egLlbuyUlen+QJSZ6a5H5J/rCqzpuzz7VJviPJc/v7/5Mk+9e4Trrrck2T5Ndy6r368rUskmU5nOQVSR6T5LFJ/jjJ26vq0v529+j6c6ZrmrhH162qelySH0jyoXmbzvpeNY35JlJVLclzWmu/2/9eSe5I8p9aa7/Qb5tM8qkkL2it/fawaqWb+de03/amJFtba88eUlmcparaluTTSZ7cWvvT/n15LMnzWms39Pf5p0k+muSJrbX3D69auph/TfttNyf5YGvtqiGWxlmoqs8m+bdJboh7dEOYvaattV93j65fVXV+kr9O8oNJfjz96zio/z/VA7W5PSTJVyZ592xDa20qyZ8neeKwimIg9vSHDX2sqn65qh447IJYlsn++2f7749Jrwdj7r36t0lui3t1vZh/TWd9T1X9Y1X9TVW9pqq+fK0LY/mqaqyqviu9EQHvi3t03Vvgms5yj65Pr0/yztbau+e1D+RePXcQFbJufWX//VPz2j81Zxvrzx+k1xV9KMnDkvzHJDdW1RNbazNDrYwzqqpzklyX5H+31v6m3/yVSU621o7P2929ug4sck2T5C1JPpneSICvS/KzSR6RZO9a10g3VXVZen9cf1mSz6U3AuAjVXV53KPr0mLXtL/ZPboO9YPwo5M8boHNA/n/UwEKNph5Qy8/XFUfSvJ3SfYkec9QimI5Xp/ka5N847ALYWAWvKattV+d8/XDVXU0yXuq6mGttb9bywLp7GNJLk+vR/HKJG+uqicPtSLO1oLXtLX2Effo+lNVO5Ncn+SprbUvrNbPMYRvc/uH/vv8mUe+Ys421rnW2t8n+ccku4ZdC0urqtcleUaSK1prh+ds+ockW6pq67xD3KsjbolrupA/77+7V0dUa+1ka+1ga+2vWmtXpzehz764R9etJa7pQtyjo+8xSR6c5K+r6p6quie9iSJ+qP/5UxnAvSpAbW6H0vsvy1NmG6pqIr3Z+N632EGsL1W1I8kDkxwddi0srHpel+Q5Sb6ptXZo3i5/leSLOfVefUSSi+NeHUkdrulCLu+/u1fXj3OSjMc9upHMXtOFXN5/d4+OrvckuSy9azX7+kCS35zz+azvVUP4Nrj+LCRz/6XkIf2x2p9trd3Wnxf/x6vq4+kFqlenN9b3d9e4VDpa6pr2X69K8jvpheOHJfm5JAeTvGttK2UZXp/keUmeleSuqpodhz3VWru7tTZVVb+e5Jr+DFHTSX4pyfvM7jWylrymVfWw/vbfT/KZ9J6vuDbJn7bW5k+5ywioqtckuTG9h80vSO/67UnyNPfo+rTUNXWPrk+ttbuSzH3WNFX1+SSfmX0GdRD3qgC18T02yU1zvl/Tf39zkhek98f1eUl+NcnWJO9N8q2rOW6Us7bUNX1xev8j//z0rucdSf4wyU+01k6sYY0sz4v77zfPa39hkjf1P/9wknvTC8fj6QXiH1yD2liZM13Tk0m+OclV6f1v8O3pXdufXpPqWIkHJ/mN9NYCmkpvbZmntdb+qL/dPbr+LHpN+8/SuEc3prO+V60DBQAA0JFnoAAAADoSoAAAADoSoAAAADoSoAAAADoSoAAAADoSoAAAADoSoAAAADoSoABYM1V1c1Vdd4Z9PlFVV63W+QHgbAhQAIyaxyX51aV2qKo9VdWqauvalDSaNQCw9s4ddgEAMFdr7dhS26vqfqv586tqS2vt5Gr+DADWLz1QAKy1c6vqdVU1VVX/WFWvrqqa3Th/CF+/l+fFVfV7VfX5JL+W5Kb+5jv729805/znVNXPVdVnq+ofquo/LFVMVb2pqn63qn6squ5I8rF++/9XVR+oqrv653lLVT24v+2SxWqoqnOq6uqqOlRVd1fVLVV15cp/XQCMEgEKgLX2/CT3JPn6JPuS/EiSf3WGY/5DkrcluSzJq5J8Z7/9EUm2988z9/yfT/L4JC9P8u+r6qlnOP9T+ud6apJn9Nvul+QnkjwyybOTXJLkTf1tty9Rw9VJvi/Ji5JcmuTaJP+9qp58hhoAWAcM4QNgrd2e5Idbay3Jx6rqsiQ/nF7P0mLe0lp74+yXqnpI/+OnW2vH5+37odbaT/Y/f7yqXppeQPqjJc7/+ST/au7QvdbaG+Zs//uq+qEkf1lV57fWPldVn51fQ1WNJ3llkm9urb1vzrHfmOQHkvzJEjUAsA7ogQJgrb2/H55mvS/Jw6tqbIljPrCM839o3vejSR58hmM+PP+5p6p6TFW9o6puq6q7cl/4uXiJ8+xK8uVJ/qiqPjf7Sq9H6mHd/yMAMKr0QAGwHnx+Gft+cd73ljP/g+Ep56+q85K8q//6niTH0gtO70qyZYnznN9///YkR+ZtO3GGGgBYBwQoANba4+d9f0KSj7fWZpZxjtneoqV6rc7GP03ywCSvaK3dniRV9dgONXwkvaB0cWvNcD2ADcgQPgDW2sVVdU1VPaKqvjvJy5Jcv8xzfDK9nqVnVNW2qjr/TAcs023pBaSXVdVDq+qZ6U0osWQNrbW7kvxCkmur6vlV9bCqenRVvayqnj/gGgEYAgEKgLX2G0nun+Qvkrw+vfC05MK587XWjqQ3G99rk3wqyesGWWB/LaoXJHluer1Kr0jybzrW8BNJXp3ebHwfTfIH6Q3pOzTIGgEYjjr1OV4AAAAWowcKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgIwEKAACgo/8fLr04waJKne4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "fig=plt.figure(figsize=(10,6), dpi= 100)\n",
    "\n",
    "palette = itertools.cycle(['b','r','m'])\n",
    "for c in range(3):\n",
    "  cclusterx = [ x[1] for x in countriesdata if cpredictions[x[0]] == c]               \n",
    "  cclustery = [ x[2] for x in countriesdata if cpredictions[x[0]] == c]  \n",
    "  plt.scatter(cclusterx,cclustery,color=next(palette) )\n",
    "     \n",
    "centersX = [ x[0] for x in countriesclusters1.centers ]\n",
    "centersY = [ x[1] for x in countriesclusters1.centers ]\n",
    "# Plot the center of each cluster\n",
    "plt.scatter(centersX, centersY, marker='x', s=100, linewidths=3, color=['b','r','m'], zorder=10) \n",
    "\n",
    "plt.xlabel('birth rate')\n",
    "plt.ylabel('death rate')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example domain: clustering similar users\n",
    "\n",
    "Let's now turn our attention to the topic of discovering similar users for recommender systems. In particular, let's consider a data base of users, where for each user we store the ratings given by the user to different movies. We will talk more about recommender systems later in this course, dicussing more appropriate ways of dealing with such data, where tipically many entries (actually most of the entries) of such user-product matrix will be empty, so this clustering approach may not be always usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Example data\n",
    "#\n",
    "# We have 10 users, and 10 movies: STW1, STW2, STW3, STW4, STW5, STW6\n",
    "#                                  T1, T2, T3 and BaT\n",
    "# Each entry i,j is the rating given by the user in the range [-5.0,5.0]\n",
    "# We can observe that we have 4 clear Star Wars fans (that they also like a \n",
    "# little bit Terminator movies)\n",
    "# We also have four clear Terminator fans (that they also like a little STWs movies)\n",
    "# Finally, we have two clear Breakfast at tiffannies fans (BaT), that they do not\n",
    "# like too much science-fiction movies\n",
    "\n",
    "usersandmovies = [ [3,3,3,5,5,4, 3,3,-1, -1], \\\n",
    "                   [3,3,3,5,5,4, 4,2,0, -1], \\\n",
    "                   [3,3,4,5,5,4, 4,4,1, 0], \\\n",
    "                   [4,3,3,4,5,4, 3,3,1, -1], \\\n",
    "                   [1,1,1,0,1,1, 5,4,2, -1], \\\n",
    "                   [1,2,1,0,1,1, 4,4,2, -1], \\\n",
    "                   [1,2,2,1,1,1, 4,4,2, -1], \\\n",
    "                   [1,2,2,1,1,0, 5,4,3, -1], \\\n",
    "                   [-2,-3,-2,0,-2,-1, 0,0,-1,4], \\\n",
    "                   [-2,-3,-2,0,-2,-1, 0,0,-1,4]   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The code we use for discovering three clusters in this second data set is almost identical to the previous one, given that the input data format is almost the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "usersandmoviesRDD = sc.parallelize( usersandmovies ).map( lambda p : np.array(p) )\n",
    "usersandmoviesRDD.persist()\n",
    "\n",
    "# Cluster the data in 3 clusters\n",
    "userclusters1 = KMeans.train( usersandmoviesRDD, 3, maxIterations= 5, \\\n",
    "                               initializationMode=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster for  [3, 3, 3, 5, 5, 4, 3, 3, -1, -1]  :  1\n",
      "Cluster for  [3, 3, 3, 5, 5, 4, 4, 2, 0, -1]  :  1\n",
      "Cluster for  [3, 3, 4, 5, 5, 4, 4, 4, 1, 0]  :  1\n",
      "Cluster for  [4, 3, 3, 4, 5, 4, 3, 3, 1, -1]  :  1\n",
      "Cluster for  [1, 1, 1, 0, 1, 1, 5, 4, 2, -1]  :  0\n",
      "Cluster for  [1, 2, 1, 0, 1, 1, 4, 4, 2, -1]  :  0\n",
      "Cluster for  [1, 2, 2, 1, 1, 1, 4, 4, 2, -1]  :  0\n",
      "Cluster for  [1, 2, 2, 1, 1, 0, 5, 4, 3, -1]  :  0\n",
      "Cluster for  [-2, -3, -2, 0, -2, -1, 0, 0, -1, 4]  :  2\n",
      "Cluster for  [-2, -3, -2, 0, -2, -1, 0, 0, -1, 4]  :  2\n",
      "Within Cluster Sum of Squared Error = 14.0\n"
     ]
    }
   ],
   "source": [
    "for user in usersandmovies:\n",
    "    print (\"Cluster for \", user, \" : \", userclusters1.predict(np.array(user)))\n",
    "\n",
    "WCSSE = usersandmoviesRDD.map(lambda point: error(userclusters1,point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Cluster Sum of Squared Error = \" + str(WCSSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observe that in *almost all* the executions of k-means with this data set, we discover the three subgroups of user profiles we have intentionally introduced in this data set of user movie reviews. However, in some executions the clusters discovered differ slightly, and the WCSSE increases from 14 to 180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  The bisecting k-means algorithm \n",
    "\n",
    "\n",
    "This algorithm is a variant of the k-means algorithm, that works by creating a tree of clusters, being the final set of k leaf clusters the clusters finally provided. The original version is from the paper \"A comparison of document clustering techniques\", by Steinbach, Karypis, and Kumar:\n",
    "\n",
    " https://www.researchgate.net/publication/2628533_A_Comparison_of_Document_Clustering_Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We present here the version implemented in Spark, in pseudo-code:\n",
    "\n",
    "\n",
    "```python\n",
    "level=0\n",
    "# Start with a single cluster, but we want to have k\n",
    "Clusters[level] = [[All the points]] \n",
    "while ( len(Clusters[level]) < k and\n",
    "         there are divisible clusters):\n",
    "   tobisect = pickDivisibleClusters(Clusters[level])\n",
    "   # Make two child clusters from each cluster in tobisect:       \n",
    "   Clusters[level+1] =\n",
    "       [RunKmeans(cluster,2,maxIterations) | for cluster in tobisect]\n",
    "   level=level+1    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The bisecting steps of clusters on the same level are executed in parallel.\n",
    "- If bisecting all divisible clusters on the curent level would result in more than `k` leaf clusters, larger clusters will be the ones picked\n",
    "- A cluster is divisible if its number of points is above certain **minimum number of points**\n",
    "> It may be necessary to set this minimum value not too small, to avoid overfiting problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, let's see this Bisecting k-means algorithm executed in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import BisectingKMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Cluster the data in 3 clusters, but starting from one big cluster\n",
    "# and bisecting clusters until we finally get k (3) clusters\n",
    "userclusters2 = BisectingKMeans.train( usersandmoviesRDD, 3, maxIterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster for  [3, 3, 3, 5, 5, 4, 3, 3, -1, -1]  :  2\n",
      "Cluster for  [3, 3, 3, 5, 5, 4, 4, 2, 0, -1]  :  2\n",
      "Cluster for  [3, 3, 4, 5, 5, 4, 4, 4, 1, 0]  :  2\n",
      "Cluster for  [4, 3, 3, 4, 5, 4, 3, 3, 1, -1]  :  2\n",
      "Cluster for  [1, 1, 1, 0, 1, 1, 5, 4, 2, -1]  :  1\n",
      "Cluster for  [1, 2, 1, 0, 1, 1, 4, 4, 2, -1]  :  1\n",
      "Cluster for  [1, 2, 2, 1, 1, 1, 4, 4, 2, -1]  :  1\n",
      "Cluster for  [1, 2, 2, 1, 1, 0, 5, 4, 3, -1]  :  1\n",
      "Cluster for  [-2, -3, -2, 0, -2, -1, 0, 0, -1, 4]  :  0\n",
      "Cluster for  [-2, -3, -2, 0, -2, -1, 0, 0, -1, 4]  :  0\n",
      "Within Cluster Sum of Squared Error = 14.0\n"
     ]
    }
   ],
   "source": [
    "for user in usersandmovies:\n",
    "    print (\"Cluster for \", user, \" : \", userclusters2.predict(np.array(user)))\n",
    "\n",
    "WCSSE = userclusters2.computeCost(usersandmoviesRDD)\n",
    "print(\"Within Cluster Sum of Squared Error = \" + str(WCSSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
